{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Hindi Movies Scraper\n",
    "\n",
    "This notebook scrapes data about Hindi movies from IMDb using Selenium WebDriver.\n",
    "\n",
    "## Features\n",
    "- Scrapes movie titles, IDs, descriptions, release dates, and ratings\n",
    "- Handles pagination automatically\n",
    "- Saves results to CSV files\n",
    "- Deduplicates movies across batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define utility functions for extracting movie information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_id(movie_url):\n",
    "    \"\"\"Extract the IMDb movie ID from the URL\"\"\"\n",
    "    if not movie_url:\n",
    "        return \"\"\n",
    "    match = re.search(r'tt\\d+', movie_url)\n",
    "    return match.group(0) if match else \"\"\n",
    "\n",
    "def wait_for_element(driver, selector, timeout=10):\n",
    "    \"\"\"Wait for an element to be present on the page\"\"\"\n",
    "    try:\n",
    "        element = WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "        )\n",
    "        return element\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout waiting for element with selector: {selector}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Movie Data Extraction Functions\n",
    "\n",
    "Functions to extract specific movie details from HTML elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_data(element, driver):\n",
    "    \"\"\"Extract all movie data from a single element\"\"\"\n",
    "    # TITLE EXTRACTION - Try multiple methods\n",
    "    title_element = None\n",
    "    movie_name = \"N/A\"\n",
    "    \n",
    "    # Try multiple selectors for the title element\n",
    "    title_selectors = [\n",
    "        \"h3.lister-item-header a\",\n",
    "        \"h3 a\",\n",
    "        \"a[href*='/title/tt']\",\n",
    "        \".ipc-title-link-wrapper\",\n",
    "        \".ipc-title a\"\n",
    "    ]\n",
    "    \n",
    "    for selector in title_selectors:\n",
    "        try:\n",
    "            title_elements = element.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if title_elements:\n",
    "                title_element = title_elements[0]\n",
    "                movie_name = title_element.text.strip()\n",
    "                if movie_name:  # If we found a non-empty title\n",
    "                    break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # If we still don't have a title element, try another approach\n",
    "    if not title_element or not movie_name or movie_name == \"N/A\":\n",
    "        try:\n",
    "            # Try to find any header element that might contain the title\n",
    "            header_elements = element.find_elements(By.CSS_SELECTOR, \"h3, h1, h2, h4\")\n",
    "            for header in header_elements:\n",
    "                text = header.text.strip()\n",
    "                if text and len(text) > 1:  # Non-empty text that's at least 2 characters\n",
    "                    movie_name = text\n",
    "                    # If there's a year in parentheses, remove it\n",
    "                    movie_name = re.sub(r'\\s+\\(\\d{4}\\)$', '', movie_name)\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Get movie URL and ID if we have a title element\n",
    "    movie_url = \"\"\n",
    "    movie_id = \"\"\n",
    "    if title_element:\n",
    "        try:\n",
    "            movie_url = title_element.get_attribute(\"href\")\n",
    "            movie_id = extract_movie_id(movie_url)\n",
    "        except:\n",
    "            # If we can't get the URL from the title element, try to find it elsewhere\n",
    "            link_elements = element.find_elements(By.CSS_SELECTOR, \"a[href*='/title/tt']\")\n",
    "            if link_elements:\n",
    "                movie_url = link_elements[0].get_attribute(\"href\")\n",
    "                movie_id = extract_movie_id(movie_url)\n",
    "    \n",
    "    # If we still don't have a movie ID, skip this element\n",
    "    if not movie_id:\n",
    "        return None\n",
    "    \n",
    "    # Extract other details\n",
    "    description = extract_description(element)\n",
    "    release_date = extract_release_date(element)\n",
    "    rating = extract_rating(element)\n",
    "    \n",
    "    return {\n",
    "        'movie_id': movie_id,\n",
    "        'movie_name': movie_name,\n",
    "        'description': description,\n",
    "        'release_date': release_date,\n",
    "        'rating': rating\n",
    "    }\n",
    "\n",
    "def extract_description(element):\n",
    "    \"\"\"Extract movie description from element\"\"\"\n",
    "    description = \"N/A\"\n",
    "    try:\n",
    "        # Try different selectors for the description\n",
    "        desc_selectors = [\n",
    "            \"p.text-muted\", \n",
    "            \".overview-text\", \n",
    "            \"p.ipc-html-content-inner-div\", \n",
    "            \".ipc-html-content-inner-div\",\n",
    "            \".plot-summary\"\n",
    "        ]\n",
    "        for desc_selector in desc_selectors:\n",
    "            try:\n",
    "                desc_elements = element.find_elements(By.CSS_SELECTOR, desc_selector)\n",
    "                if len(desc_elements) > 1:  # Usually the second paragraph contains the description\n",
    "                    description = desc_elements[1].text.strip()\n",
    "                    break\n",
    "                elif len(desc_elements) == 1:\n",
    "                    description = desc_elements[0].text.strip()\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return description\n",
    "\n",
    "def extract_release_date(element):\n",
    "    \"\"\"Extract release date from element\"\"\"\n",
    "    release_date = \"N/A\"\n",
    "    try:\n",
    "        # Try different selectors for the year\n",
    "        year_selectors = [\n",
    "            \".lister-item-year\", \n",
    "            \".year_type\", \n",
    "            \".text-muted .ipc-metadata-list-summary-item__t\", \n",
    "            \".dli-title-metadata-item\",\n",
    "            \"span.text-muted\"\n",
    "        ]\n",
    "        for year_selector in year_selectors:\n",
    "            try:\n",
    "                year_elements = element.find_elements(By.CSS_SELECTOR, year_selector)\n",
    "                if year_elements:\n",
    "                    year_text = year_elements[0].text.strip()\n",
    "                    # Look for years in format (2020) or (2020-2022)\n",
    "                    year_match = re.search(r'\\((\\d{4}(?:-\\d{4})?)\\)', year_text)\n",
    "                    if year_match:\n",
    "                        release_date = year_match.group(1)\n",
    "                    else:\n",
    "                        # If no parentheses, try to extract just the years\n",
    "                        release_date = re.sub(r'[^\\dâ€“-]', '', year_text)\n",
    "                    if release_date:\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return release_date\n",
    "\n",
    "def extract_rating(element):\n",
    "    \"\"\"Extract rating from element\"\"\"\n",
    "    rating = \"N/A\"\n",
    "    try:\n",
    "        # Try different selectors for the rating\n",
    "        rating_selectors = [\n",
    "            \".ratings-imdb-rating strong\", \n",
    "            \".ipc-rating-star--imdb\", \n",
    "            \".ipc-rating-star\", \n",
    "            \".rating-ineligible\",\n",
    "            \".inline-block.ratings-imdb-rating\"\n",
    "        ]\n",
    "        for rating_selector in rating_selectors:\n",
    "            try:\n",
    "                rating_elements = element.find_elements(By.CSS_SELECTOR, rating_selector)\n",
    "                if rating_elements:\n",
    "                    rating_text = rating_elements[0].text.strip()\n",
    "                    # Clean up rating\n",
    "                    rating_match = re.search(r'(\\d+\\.\\d+|\\d+)', rating_text)\n",
    "                    if rating_match:\n",
    "                        rating = rating_match.group(1)\n",
    "                    else:\n",
    "                        rating = rating_text\n",
    "                    if rating:\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Scraping Function\n",
    "\n",
    "Main function to scrape multiple batches of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_multiple_batches(base_url, num_batches=3):\n",
    "    \"\"\"Scrape multiple batches of 50 movies each using the 'load more' button\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")  # Ensures full page is loaded\n",
    "    \n",
    "    # Add user agent\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    \n",
    "    all_movie_data = []\n",
    "    batch_movie_data = {}\n",
    "    processed_ids = set()\n",
    "    \n",
    "    try:\n",
    "        print(f\"Starting Chrome WebDriver to access: {base_url}\")\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(base_url)\n",
    "        \n",
    "        # Wait for the initial page to load\n",
    "        if not wait_for_element(driver, \".lister-item, .ipc-metadata-list-summary-item\"):\n",
    "            print(\"Failed to load initial movie list\")\n",
    "            return all_movie_data, batch_movie_data\n",
    "        \n",
    "        print(\"Initial page loaded successfully\")\n",
    "        \n",
    "        # For each batch of 50 movies\n",
    "        for batch_num in range(1, num_batches + 1):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing batch {batch_num} of {num_batches}...\")\n",
    "            \n",
    "            # Scroll to ensure all content is loaded\n",
    "            print(\"Scrolling to load all content...\")\n",
    "            for _ in range(5):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Save debug HTML for this batch\n",
    "            debug_filename = f\"debug_imdb_batch_{batch_num}.html\"\n",
    "            with open(debug_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(driver.page_source)\n",
    "            print(f\"Saved HTML for batch {batch_num} to {debug_filename}\")\n",
    "            \n",
    "            # Find all movie containers\n",
    "            selectors = [\n",
    "                \".lister-item\",  # Old IMDb layout\n",
    "                \".ipc-metadata-list-summary-item\",  # New layout\n",
    "                \".sc-77a2c808-0.jwpHns\", # Another new layout class\n",
    "                \".ipc-page-grid__item\" # Yet another possible container\n",
    "            ]\n",
    "            \n",
    "            movie_elements = []\n",
    "            for selector in selectors:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                if elements:\n",
    "                    print(f\"Found {len(elements)} movie elements with selector '{selector}'\")\n",
    "                    movie_elements = elements\n",
    "                    if len(elements) >= 40:  # If we found a significant number, this is likely the right selector\n",
    "                        break\n",
    "            \n",
    "            # Extract movie data from this batch\n",
    "            batch_data = []\n",
    "            \n",
    "            for i, element in enumerate(movie_elements):\n",
    "                try:\n",
    "                    # Calculate absolute position of this movie across all batches\n",
    "                    absolute_position = (batch_num - 1) * 50 + i + 1\n",
    "                    \n",
    "                    # If this is not the first batch, we need to check if we've already processed this movie\n",
    "                    # We'll use the element's position to determine if it's new or old\n",
    "                    if batch_num > 1 and i < 50 * (batch_num - 1):\n",
    "                        # This is an already processed movie from a previous batch\n",
    "                        continue\n",
    "                    \n",
    "                    print(f\"Processing movie #{absolute_position} (batch {batch_num}, position {i+1}):\")\n",
    "                    \n",
    "                    # Extract movie data using our helper functions\n",
    "                    movie_data = extract_movie_data(element, driver)\n",
    "                    \n",
    "                    if not movie_data:\n",
    "                        print(f\"  Skipping - Could not extract data\")\n",
    "                        continue\n",
    "                    \n",
    "                    movie_id = movie_data['movie_id']\n",
    "                    \n",
    "                    # Skip if we've already processed this ID\n",
    "                    if movie_id in processed_ids:\n",
    "                        print(f\"  Skipping - Duplicate ID: {movie_id}\")\n",
    "                        continue\n",
    "                    \n",
    "                    processed_ids.add(movie_id)\n",
    "                    movie_data['batch'] = batch_num\n",
    "                    \n",
    "                    print(f\"  Title: '{movie_data['movie_name']}'\")\n",
    "                    print(f\"  ID: {movie_id}\")\n",
    "                    \n",
    "                    batch_data.append(movie_data)\n",
    "                    all_movie_data.append(movie_data)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing movie element: {e}\")\n",
    "            \n",
    "            print(f\"Extracted {len(batch_data)} new unique movies in batch {batch_num}\")\n",
    "            batch_movie_data[batch_num] = batch_data\n",
    "            \n",
    "            # If we need more batches, click \"50 more\" button if available\n",
    "            if batch_num < num_batches:\n",
    "                try:\n",
    "                    # Look for the \"50 more\" button - try different possible selectors\n",
    "                    load_more_selectors = [\n",
    "                        \".lister-page-next\",\n",
    "                        \".ipc-see-more__button\",\n",
    "                        \"a.flat-button.lister-page-next.next-page\",\n",
    "                        \"a[class*='next-page']\",\n",
    "                        \"a[href*='&start=']\"\n",
    "                    ]\n",
    "                    \n",
    "                    load_more_button = None\n",
    "                    for selector in load_more_selectors:\n",
    "                        try:\n",
    "                            buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                            for button in buttons:\n",
    "                                if \"more\" in button.text.lower() or \"next\" in button.text.lower():\n",
    "                                    load_more_button = button\n",
    "                                    break\n",
    "                            if load_more_button:\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if not load_more_button:\n",
    "                        print(\"Could not find 'Load More' or 'Next' button, trying URL-based pagination\")\n",
    "                        # Fall back to URL-based pagination\n",
    "                        next_url = f\"{base_url}&start={(batch_num * 50) + 1}&ref_=adv_nxt\"\n",
    "                        print(f\"Navigating to next batch URL: {next_url}\")\n",
    "                        driver.get(next_url)\n",
    "                    else:\n",
    "                        print(f\"Found '{load_more_button.text}' button, clicking to load more movies\")\n",
    "                        # Scroll to make the button visible\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)\n",
    "                        time.sleep(1)  # Wait for button to be clickable\n",
    "                        load_more_button.click()\n",
    "                    \n",
    "                    # Wait for the new content to load\n",
    "                    print(\"Waiting for next batch to load...\")\n",
    "                    time.sleep(5)  # Give it some time to load\n",
    "                    \n",
    "                    # Verify that we have more movies now\n",
    "                    new_count = len(driver.find_elements(By.CSS_SELECTOR, \".lister-item, .ipc-metadata-list-summary-item\"))\n",
    "                    print(f\"Now showing {new_count} total movies on page\")\n",
    "                    \n",
    "                    if new_count <= 50 * batch_num:\n",
    "                        print(\"Warning: No new movies loaded, trying alternative pagination\")\n",
    "                        # Try direct URL navigation as a fallback\n",
    "                        next_url = f\"{base_url}&start={(batch_num * 50) + 1}&ref_=adv_nxt\"\n",
    "                        print(f\"Navigating to: {next_url}\")\n",
    "                        driver.get(next_url)\n",
    "                        time.sleep(3)  # Wait for page to load\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error navigating to next batch: {e}\")\n",
    "                    print(\"Trying direct URL navigation\")\n",
    "                    try:\n",
    "                        next_url = f\"{base_url}&start={(batch_num * 50) + 1}&ref_=adv_nxt\"\n",
    "                        print(f\"Navigating to: {next_url}\")\n",
    "                        driver.get(next_url)\n",
    "                        time.sleep(3)  # Wait for page to load\n",
    "                    except:\n",
    "                        print(\"Failed to navigate to next batch\")\n",
    "                        break\n",
    "        \n",
    "        return all_movie_data, batch_movie_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in scraping process: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return all_movie_data, batch_movie_data\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "            print(\"Closed browser\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CSV Export Function\n",
    "\n",
    "Function to save the extracted movie data to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename='imdb_hindi_movies.csv'):\n",
    "    \"\"\"Save the extracted data to a CSV file\"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to save.\")\n",
    "        return False\n",
    "    \n",
    "    # Debug: Print summary of movies to be saved\n",
    "    print(f\"\\nSaving {len(data)} movies to {filename}\")\n",
    "    if len(data) > 0:\n",
    "        print(\"Sample of movies being saved:\")\n",
    "        for i, movie in enumerate(data[:5]):  # Just show first 5 for brevity\n",
    "            print(f\"{i+1}. {movie['movie_name']} (ID: {movie['movie_id']}, Batch: {movie.get('batch', 'N/A')})\")\n",
    "        if len(data) > 5:\n",
    "            print(f\"... and {len(data) - 5} more movies\")\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['movie_id', 'movie_name', 'description', 'release_date', 'rating', 'batch']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for movie in data:\n",
    "            # Ensure movie name is not empty\n",
    "            if not movie['movie_name'] or movie['movie_name'] == 'N/A':\n",
    "                print(f\"Warning: Movie with ID {movie['movie_id']} has no name!\")\n",
    "            \n",
    "            # Write the row with explicit field mapping to avoid any issues\n",
    "            row = {\n",
    "                'movie_id': movie['movie_id'],\n",
    "                'movie_name': movie['movie_name'],\n",
    "                'description': movie['description'],\n",
    "                'release_date': movie['release_date'],\n",
    "                'rating': movie['rating'],\n",
    "                'batch': movie.get('batch', 'N/A')\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"\\nData saved to {filename}\")\n",
    "    \n",
    "    # Verify the CSV file was created correctly\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            first_few_lines = [next(f) for _ in range(min(6, len(data) + 1))]  # Read header + first 5 rows (or fewer if less data)\n",
    "        \n",
    "        print(f\"\\nVerifying CSV file content for {filename}:\")\n",
    "        for line in first_few_lines:\n",
    "            print(line.strip())\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying CSV file {filename}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Helper Function for Finding Total Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_results(driver):\n",
    "    \"\"\"Try to get the total number of results from the page\"\"\"\n",
    "    try:\n",
    "        # Look for the text that shows total results\n",
    "        result_count_elements = driver.find_elements(By.CSS_SELECTOR, \".desc span\")\n",
    "        for element in result_count_elements:\n",
    "            text = element.text\n",
    "            # Look for text like \"1-50 of 12,345 titles\"\n",
    "            match = re.search(r'of ([\\d,]+)', text)\n",
    "            if match:\n",
    "                total = match.group(1).replace(',', '')\n",
    "                return int(total)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Default if we can't determine\n",
    "    return 1000  # Assume a large number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Function\n",
    "\n",
    "This is the entry point of the script. You can adjust the number of batches to scrape by changing the value of `num_batches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    base_url = \"https://www.imdb.com/search/title/?title_type=feature&countries=IN&languages=hi\"\n",
    "    \n",
    "    # Determine how many batches to scrape\n",
    "    num_batches = 170  # Set to how many batches of 50 you want to scrape\n",
    "    \n",
    "    try:\n",
    "        # Scrape all batches in a single browser session\n",
    "        all_movie_data, batch_movie_data = scrape_multiple_batches(base_url, num_batches)\n",
    "        \n",
    "        print(f\"\\nTotal unique movies scraped across all batches: {len(all_movie_data)}\")\n",
    "        \n",
    "        # Save combined CSV\n",
    "        save_to_csv(all_movie_data)\n",
    "        \n",
    "        # Also save a separate CSV for each batch\n",
    "        print(\"\\nSaving individual batch CSV files...\")\n",
    "        for batch_num, movies in batch_movie_data.items():\n",
    "            # Verify we have different movies on each batch by printing the first movie ID\n",
    "            if movies:\n",
    "                print(f\"Batch {batch_num} first movie: {movies[0]['movie_name']} (ID: {movies[0]['movie_id']})\")\n",
    "            \n",
    "            # Save batch-specific CSV\n",
    "            batch_filename = f'imdb_hindi_movies_batch{batch_num}.csv'\n",
    "            if save_to_csv(movies, batch_filename):\n",
    "                print(f\"Successfully saved {len(movies)} movies from batch {batch_num} to {batch_filename}\")\n",
    "        \n",
    "        # Print batch summary for debugging\n",
    "        print(\"\\nMovie summary by batch:\")\n",
    "        for batch_num, movies in batch_movie_data.items():\n",
    "            print(f\"Batch {batch_num}: {len(movies)} movies\")\n",
    "            if movies:\n",
    "                print(f\"  First few: {[movie['movie_name'] for movie in movies[:3]]}\")\n",
    "                if len(movies) > 3:\n",
    "                    print(f\"  Last few: {[movie['movie_name'] for movie in movies[-3:]]}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main process: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run the Scraper\n",
    "\n",
    "Execute the main function to start the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
