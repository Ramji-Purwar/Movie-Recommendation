{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Bollywood Movie Data Scraper\n",
    "\n",
    "This notebook scrapes data about Hindi-language films from India on IMDb in two phases:\n",
    "1. Collecting basic information from the search results page\n",
    "2. Collecting detailed information from individual movie pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='imdb_scraping.log',\n",
    "    filemode='w'\n",
    ")\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables and constants\n",
    "SEARCH_URL = 'https://www.imdb.com/search/title/?title_type=feature&countries=IN&languages=hi'\n",
    "MOVIE_BASE_URL = 'https://www.imdb.com/title/'\n",
    "CURRENT_TIME = \"2025-05-15 10:20:15\"  # datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "USER_LOGIN = \"Ramji-Purwar\"\n",
    "\n",
    "# Create a session with browser-like headers\n",
    "session = requests.Session()\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Referer': 'https://www.imdb.com/',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_search_page(url, max_movies=None):\n",
    "    \"\"\"\n",
    "    PHASE 1: Scrape basic movie information from IMDb search results page\n",
    "    \"\"\"\n",
    "    logging.info(f\"Scraping search results from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"Failed to retrieve search page: Status code {response.status_code}\")\n",
    "            return []\n",
    "            \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find movie items\n",
    "        movie_items = soup.find_all('div', class_=lambda c: c and 'lister-item' in c)\n",
    "        \n",
    "        if not movie_items:\n",
    "            logging.warning(\"No movie items found with primary selector. Trying alternative selectors...\")\n",
    "            movie_items = soup.select(\".lister-list .lister-item\")\n",
    "        \n",
    "        if not movie_items:\n",
    "            logging.warning(\"Still no movie items found. Saving HTML for debugging...\")\n",
    "            with open(\"imdb_search_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(str(soup))\n",
    "            return []\n",
    "        \n",
    "        logging.info(f\"Found {len(movie_items)} movie items\")\n",
    "        \n",
    "        # Limit number of movies if specified\n",
    "        if max_movies and max_movies < len(movie_items):\n",
    "            movie_items = movie_items[:max_movies]\n",
    "        \n",
    "        movies_data = []\n",
    "        for item in movie_items:\n",
    "            try:\n",
    "                # Extract movie ID\n",
    "                movie_id = None\n",
    "                link = item.select_one('a[href*=\"/title/tt\"]')\n",
    "                if link:\n",
    "                    href = link.get('href', '')\n",
    "                    id_match = re.search(r'/title/(tt\\d+)', href)\n",
    "                    if id_match:\n",
    "                        movie_id = id_match.group(1)\n",
    "                \n",
    "                if not movie_id:\n",
    "                    continue\n",
    "                \n",
    "                # Extract movie name\n",
    "                name_elem = item.select_one('h3 a')\n",
    "                movie_name = name_elem.get_text(strip=True) if name_elem else None\n",
    "                \n",
    "                # Extract year\n",
    "                year_elem = item.select_one('.lister-item-year')\n",
    "                year = None\n",
    "                if year_elem:\n",
    "                    year_text = year_elem.get_text(strip=True)\n",
    "                    year_match = re.search(r'(\\d{4})', year_text)\n",
    "                    if year_match:\n",
    "                        year = year_match.group(1)\n",
    "                \n",
    "                # Extract description\n",
    "                desc_elem = item.select_one('p.text-muted:nth-of-type(2)')\n",
    "                description = None\n",
    "                if desc_elem:\n",
    "                    description = desc_elem.get_text(strip=True)\n",
    "                    # Remove newlines and excessive whitespace\n",
    "                    description = re.sub(r'\\s+', ' ', description).strip()\n",
    "                \n",
    "                movies_data.append({\n",
    "                    'movie_id': movie_id,\n",
    "                    'movie_name': movie_name,\n",
    "                    'description': description,\n",
    "                    'year': year,\n",
    "                    'scrape_time': CURRENT_TIME,\n",
    "                    'user_login': USER_LOGIN\n",
    "                })\n",
    "                \n",
    "                logging.info(f\"Extracted basic info for: {movie_name} ({movie_id})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing movie item: {e}\")\n",
    "        \n",
    "        return movies_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping search page: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_details(movie_id):\n",
    "    \"\"\"\n",
    "    PHASE 2: Scrape detailed information from a movie's individual page\n",
    "    \"\"\"\n",
    "    if not movie_id:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    movie_url = f\"{MOVIE_BASE_URL}{movie_id}/\"\n",
    "    logging.info(f\"Fetching details from: {movie_url}\")\n",
    "    \n",
    "    try:\n",
    "        response = session.get(movie_url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"Failed to retrieve movie page: {response.status_code}\")\n",
    "            return None, None, None, None\n",
    "            \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract rating\n",
    "        rating = None\n",
    "        # Method 1: New IMDb layout\n",
    "        rating_elem = soup.select_one('[data-testid=\"hero-rating-bar__aggregate-rating__score\"] span')\n",
    "        if rating_elem:\n",
    "            rating = rating_elem.get_text(strip=True)\n",
    "        \n",
    "        # Method 2: Check JSON-LD data\n",
    "        if not rating:\n",
    "            script_tags = soup.select('script[type=\"application/ld+json\"]')\n",
    "            for script in script_tags:\n",
    "                try:\n",
    "                    import json\n",
    "                    json_data = json.loads(script.string)\n",
    "                    if 'aggregateRating' in json_data and 'ratingValue' in json_data['aggregateRating']:\n",
    "                        rating = str(json_data['aggregateRating']['ratingValue'])\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error parsing JSON-LD: {e}\")\n",
    "        \n",
    "        # Extract votes\n",
    "        votes = None\n",
    "        # Method 1: New IMDb layout\n",
    "        votes_elem = soup.select_one('[data-testid=\"hero-rating-bar__aggregate-rating__count\"]')\n",
    "        if votes_elem:\n",
    "            votes_text = votes_elem.get_text(strip=True)\n",
    "            votes_match = re.search(r'([\\d,]+)', votes_text)\n",
    "            if votes_match:\n",
    "                votes = votes_match.group(1).replace(',', '')\n",
    "        \n",
    "        # Method 2: Check JSON-LD data\n",
    "        if not votes:\n",
    "            script_tags = soup.select('script[type=\"application/ld+json\"]')\n",
    "            for script in script_tags:\n",
    "                try:\n",
    "                    import json\n",
    "                    json_data = json.loads(script.string)\n",
    "                    if 'aggregateRating' in json_data and 'ratingCount' in json_data['aggregateRating']:\n",
    "                        votes = str(json_data['aggregateRating']['ratingCount'])\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error parsing JSON-LD: {e}\")\n",
    "        \n",
    "        # Extract director\n",
    "        director = None\n",
    "        # Method 1: Look for director section\n",
    "        director_section = soup.select_one('[data-testid=\"title-pc-principal-credit\"]')\n",
    "        if director_section and 'Director' in director_section.get_text():\n",
    "            director_links = director_section.select('a')\n",
    "            if director_links:\n",
    "                director = director_links[0].get_text(strip=True)\n",
    "        \n",
    "        # Method 2: Look in JSON-LD data\n",
    "        if not director:\n",
    "            script_tags = soup.select('script[type=\"application/ld+json\"]')\n",
    "            for script in script_tags:\n",
    "                try:\n",
    "                    import json\n",
    "                    json_data = json.loads(script.string)\n",
    "                    if 'director' in json_data:\n",
    "                        if isinstance(json_data['director'], list):\n",
    "                            director = json_data['director'][0]['name']\n",
    "                        else:\n",
    "                            director = json_data['director']['name']\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error parsing JSON-LD: {e}\")\n",
    "        \n",
    "        # Extract top 5 actors\n",
    "        actors = []\n",
    "        # Method 1: New IMDb layout\n",
    "        cast_section = soup.select_one('[data-testid=\"title-cast\"]')\n",
    "        if cast_section:\n",
    "            actor_links = cast_section.select('a[data-testid=\"title-cast-item__actor\"]')\n",
    "            for i, actor_link in enumerate(actor_links):\n",
    "                if i >= 5:  # Limit to top 5 actors\n",
    "                    break\n",
    "                actors.append(actor_link.get_text(strip=True))\n",
    "        \n",
    "        # Method 2: Look in JSON-LD data\n",
    "        if not actors:\n",
    "            script_tags = soup.select('script[type=\"application/ld+json\"]')\n",
    "            for script in script_tags:\n",
    "                try:\n",
    "                    import json\n",
    "                    json_data = json.loads(script.string)\n",
    "                    if 'actor' in json_data:\n",
    "                        actor_data = json_data['actor']\n",
    "                        if isinstance(actor_data, list):\n",
    "                            for i, actor in enumerate(actor_data):\n",
    "                                if i >= 5:  # Limit to top 5 actors\n",
    "                                    break\n",
    "                                actors.append(actor['name'])\n",
    "                        else:\n",
    "                            actors.append(actor_data['name'])\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error parsing JSON-LD: {e}\")\n",
    "        \n",
    "        return rating, votes, director, actors\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting details for movie {movie_id}: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_with_pagination(start_page=1, end_page=2, max_movies_per_page=None):\n",
    "    \"\"\"\n",
    "    Scrape multiple pages of search results\n",
    "    \"\"\"\n",
    "    all_movies = []\n",
    "    \n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        # Calculate the start parameter based on page number\n",
    "        # Page 1 starts at 1, Page 2 starts at 51, Page 3 starts at 101, etc.\n",
    "        start_idx = 1 + (page_num - 1) * 50\n",
    "        \n",
    "        # Construct the URL with the proper start parameter\n",
    "        page_url = f\"{SEARCH_URL}&start={start_idx}&ref_=adv_nxt\"\n",
    "        \n",
    "        # Scrape the current page\n",
    "        page_movies = scrape_search_page(page_url, max_movies_per_page)\n",
    "        \n",
    "        if page_movies:\n",
    "            all_movies.extend(page_movies)\n",
    "            logging.info(f\"Added {len(page_movies)} movies from page {page_num}\")\n",
    "        else:\n",
    "            logging.warning(f\"No movies found on page {page_num}, skipping\")\n",
    "        \n",
    "        # Add a delay between pages\n",
    "        time.sleep(2 + np.random.rand() * 2)\n",
    "    \n",
    "    return all_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 10:20:15 - INFO - Scraping search results from: https://www.imdb.com/search/title/?title_type=feature&countries=IN&languages=hi&start=1&ref_=adv_nxt\n",
      "2025-05-15 10:20:16 - INFO - Found 50 movie items\n",
      "2025-05-15 10:20:16 - INFO - Extracted basic info for: The Diplomat (tt26229612)\n",
      "2025-05-15 10:20:16 - INFO - Extracted basic info for: Kesari Chapter 2: The Untold Story of Jallianwala Bagh (tt3562110)\n",
      "2025-05-15 10:20:16 - INFO - Extracted basic info for: The Bhootnii (tt27162102)\n",
      "2025-05-15 10:20:16 - INFO - Extracted basic info for: Good Bad Ugly (tt27540217)\n",
      "2025-05-15 10:20:16 - INFO - Extracted basic info for: Odela 2 (tt31529147)\n",
      "2025-05-15 10:20:16 - INFO - Added 5 movies from page 1\n"
     ]
    }
   ],
   "source": [
    "# PHASE 1: Scrape search results pages\n",
    "# Use a small number for testing\n",
    "movies_data = scrape_with_pagination(start_page=1, end_page=1, max_movies_per_page=5)\n",
    "\n",
    "# Save initial data to CSV\n",
    "initial_df = pd.DataFrame(movies_data)\n",
    "initial_df.to_csv('bollywood_movies_initial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 10:20:19 - INFO - Fetching details from: https://www.imdb.com/title/tt26229612/\n",
      "2025-05-15 10:20:20 - INFO - Fetching details from: https://www.imdb.com/title/tt3562110/\n",
      "2025-05-15 10:20:22 - INFO - Fetching details from: https://www.imdb.com/title/tt27162102/\n",
      "2025-05-15 10:20:23 - INFO - Fetching details from: https://www.imdb.com/title/tt27540217/\n",
      "2025-05-15 10:20:25 - INFO - Fetching details from: https://www.imdb.com/title/tt31529147/\n"
     ]
    }
   ],
   "source": [
    "# PHASE 2: Scrape individual movie pages\n",
    "for i, movie in enumerate(movies_data):\n",
    "    movie_id = movie['movie_id']\n",
    "    \n",
    "    # Get detailed movie information\n",
    "    rating, votes, director, actors = scrape_movie_details(movie_id)\n",
    "    \n",
    "    # Update movie data with additional details\n",
    "    movies_data[i]['rating'] = rating\n",
    "    movies_data[i]['votes'] = votes\n",
    "    movies_data[i]['director'] = director\n",
    "    movies_data[i]['actors'] = \", \".join(actors) if actors else None\n",
    "    \n",
    "    # Add a delay between requests\n",
    "    time.sleep(1 + np.random.rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>user_login</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>director</th>\n",
       "      <th>actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt26229612</td>\n",
       "      <td>The Diplomat</td>\n",
       "      <td>An Indian diplomat who tries to repatriate an ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-05-15 10:20:15</td>\n",
       "      <td>Ramji-Purwar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8822</td>\n",
       "      <td>Shivam Nair</td>\n",
       "      <td>Kubra Sait, Arunoday Singh, Harsh Chhaya, Soni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt3562110</td>\n",
       "      <td>Kesari Chapter 2: The Untold Story of Jallianw...</td>\n",
       "      <td>A dramatization of the life story of C. Sankar...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-05-15 10:20:15</td>\n",
       "      <td>Ramji-Purwar</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6668</td>\n",
       "      <td>Vinod Taliwal</td>\n",
       "      <td>Simrat Kaur, Anushka Soni, Harbhajan Mann, Pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt27162102</td>\n",
       "      <td>The Bhootnii</td>\n",
       "      <td>A female ghost who gets her heart broken by a ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-05-15 10:20:15</td>\n",
       "      <td>Ramji-Purwar</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10021</td>\n",
       "      <td>Mrighdeep Singh Lamba</td>\n",
       "      <td>Varun Sharma, Huma Qureshi, Sunny Kaushal, Ajm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt27540217</td>\n",
       "      <td>Good Bad Ugly</td>\n",
       "      <td>A story of 3 strangers who come together to so...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-05-15 10:20:15</td>\n",
       "      <td>Ramji-Purwar</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9644</td>\n",
       "      <td>Vijay Kumar Arora</td>\n",
       "      <td>Preity Zinta, Jimmy Sheirgill, Guddu Gill, Nav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt31529147</td>\n",
       "      <td>Odela 2</td>\n",
       "      <td>In a rural village known for supernatural beli...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025-05-15 10:20:15</td>\n",
       "      <td>Ramji-Purwar</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3516</td>\n",
       "      <td>Ashok Teja</td>\n",
       "      <td>Vasishta N. Simha, Hebah Patel, Yuva Chandraa,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id                                         movie_name  \\\n",
       "0  tt26229612                                       The Diplomat   \n",
       "1   tt3562110  Kesari Chapter 2: The Untold Story of Jallianw...   \n",
       "2  tt27162102                                       The Bhootnii   \n",
       "3  tt27540217                                      Good Bad Ugly   \n",
       "4  tt31529147                                            Odela 2   \n",
       "\n",
       "                                         description  year          scrape_time  \\\n",
       "0  An Indian diplomat who tries to repatriate an ...  2025  2025-05-15 10:20:15   \n",
       "1  A dramatization of the life story of C. Sankar...  2025  2025-05-15 10:20:15   \n",
       "2  A female ghost who gets her heart broken by a ...  2025  2025-05-15 10:20:15   \n",
       "3  A story of 3 strangers who come together to so...  2025  2025-05-15 10:20:15   \n",
       "4  In a rural village known for supernatural beli...  2024  2025-05-15 10:20:15   \n",
       "\n",
       "     user_login rating  votes               director  \\\n",
       "0  Ramji-Purwar    7.2   8822            Shivam Nair   \n",
       "1  Ramji-Purwar    8.3   6668          Vinod Taliwal   \n",
       "2  Ramji-Purwar    6.5  10021  Mrighdeep Singh Lamba   \n",
       "3  Ramji-Purwar    6.0   9644      Vijay Kumar Arora   \n",
       "4  Ramji-Purwar    5.9   3516             Ashok Teja   \n",
       "\n",
       "                                              actors  \n",
       "0  Kubra Sait, Arunoday Singh, Harsh Chhaya, Soni...  \n",
       "1  Simrat Kaur, Anushka Soni, Harbhajan Mann, Pun...  \n",
       "2  Varun Sharma, Huma Qureshi, Sunny Kaushal, Ajm...  \n",
       "3  Preity Zinta, Jimmy Sheirgill, Guddu Gill, Nav...  \n",
       "4  Vasishta N. Simha, Hebah Patel, Yuva Chandraa,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final DataFrame and save to CSV\n",
    "final_df = pd.DataFrame(movies_data)\n",
    "final_df.to_csv('bollywood_movies_complete.csv', index=False)\n",
    "\n",
    "# Show the results\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Data saved to CSV files.\n",
      "Number of movies scraped: 5\n"
     ]
    }
   ],
   "source": [
    "# Summary of results\n",
    "print(\"Scraping complete! Data saved to CSV files.\")\n",
    "print(f\"Number of movies scraped: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape more pages if needed\n",
    "def scrape_more_pages(start_page=3, end_page=5, max_movies_per_page=50):\n",
    "    \"\"\"\n",
    "    Scrape additional pages of search results and update the CSV files\n",
    "    \"\"\"\n",
    "    # Load existing data if available\n",
    "    try:\n",
    "        existing_df = pd.read_csv('bollywood_movies_complete.csv')\n",
    "        existing_ids = set(existing_df['movie_id'])\n",
    "        logging.info(f\"Loaded existing data with {len(existing_ids)} movies\")\n",
    "    except Exception:\n",
    "        existing_df = pd.DataFrame()\n",
    "        existing_ids = set()\n",
    "        logging.info(\"No existing data found, starting fresh\")\n",
    "    \n",
    "    # Scrape new pages\n",
    "    new_movies = scrape_with_pagination(start_page, end_page, max_movies_per_page)\n",
    "    \n",
    "    # Filter out movies we already have\n",
    "    unique_new_movies = [movie for movie in new_movies if movie['movie_id'] not in existing_ids]\n",
    "    logging.info(f\"Found {len(unique_new_movies)} new unique movies\")\n",
    "    \n",
    "    # Get detailed information for new movies\n",
    "    for i, movie in enumerate(unique_new_movies):\n",
    "        movie_id = movie['movie_id']\n",
    "        logging.info(f\"Processing new movie {i+1}/{len(unique_new_movies)}: {movie['movie_name']} ({movie_id})\")\n",
    "        \n",
    "        rating, votes, director, actors = scrape_movie_details(movie_id)\n",
    "        \n",
    "        # Update movie data with additional details\n",
    "        unique_new_movies[i]['rating'] = rating\n",
    "        unique_new_movies[i]['votes'] = votes\n",
    "        unique_new_movies[i]['director'] = director\n",
    "        unique_new_movies[i]['actors'] = \", \".join(actors) if actors else None\n",
    "        \n",
    "        # Add a delay between requests\n",
    "        time.sleep(1 + np.random.rand())\n",
    "    \n",
    "    # Create DataFrame for new movies\n",
    "    new_df = pd.DataFrame(unique_new_movies)\n",
    "    \n",
    "    # Combine with existing data\n",
    "    combined_df = pd.concat([existing_df, new_df], ignore_index=True) if not existing_df.empty else new_df\n",
    "    \n",
    "    # Save updated data\n",
    "    combined_df.to_csv('bollywood_movies_complete.csv', index=False)\n",
    "    logging.info(f\"Updated CSV with {len(combined_df)} total movies\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Uncomment to run this function if you want to scrape more pages\n",
    "# more_movies_df = scrape_more_pages(start_page=2, end_page=3, max_movies_per_page=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
